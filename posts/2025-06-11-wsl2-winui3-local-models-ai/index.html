<!doctype html><html lang=es><head><title>Â¿CÃ³mo ejecutar modelos de IA locales desde una app WinUI 3? Â· Christian Amado
</title><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=color-scheme content="light dark"><meta name=author content="Christian Amado"><meta name=description content="La inteligencia artificial estÃ¡ redefiniendo la experiencia del usuario en aplicaciones modernas, y las aplicaciones nativas de Windows no son la excepciÃ³n. Gracias a ONNX Runtime, es posible ejecutar modelos de inferencia de manera eficiente sin necesidad de conectarse a la nube, lo cual es ideal para escenarios desconectados, privados o de alto rendimiento.
Este artÃ­culo muestra cÃ³mo integrar un modelo ONNX en una aplicaciÃ³n WinUI 3 utilizando .NET y el paquete Microsoft.ML.OnnxRuntime. Se presentarÃ¡ un caso prÃ¡ctico de clasificaciÃ³n de imagenes con un modelo preentrenado."><meta name=keywords content="blog,desarrollador,personal"><meta name=twitter:card content="summary"><meta name=twitter:title content="Â¿CÃ³mo ejecutar modelos de IA locales desde una app WinUI 3?"><meta name=twitter:description content="La inteligencia artificial estÃ¡ redefiniendo la experiencia del usuario en aplicaciones modernas, y las aplicaciones nativas de Windows no son la excepciÃ³n. Gracias a ONNX Runtime, es posible ejecutar modelos de inferencia de manera eficiente sin necesidad de conectarse a la nube, lo cual es ideal para escenarios desconectados, privados o de alto rendimiento.
Este artÃ­culo muestra cÃ³mo integrar un modelo ONNX en una aplicaciÃ³n WinUI 3 utilizando .NET y el paquete Microsoft.ML.OnnxRuntime. Se presentarÃ¡ un caso prÃ¡ctico de clasificaciÃ³n de imagenes con un modelo preentrenado."><meta property="og:url" content="https://cmas.dev/posts/2025-06-11-wsl2-winui3-local-models-ai/"><meta property="og:site_name" content="Christian Amado"><meta property="og:title" content="Â¿CÃ³mo ejecutar modelos de IA locales desde una app WinUI 3?"><meta property="og:description" content="La inteligencia artificial estÃ¡ redefiniendo la experiencia del usuario en aplicaciones modernas, y las aplicaciones nativas de Windows no son la excepciÃ³n. Gracias a ONNX Runtime, es posible ejecutar modelos de inferencia de manera eficiente sin necesidad de conectarse a la nube, lo cual es ideal para escenarios desconectados, privados o de alto rendimiento.
Este artÃ­culo muestra cÃ³mo integrar un modelo ONNX en una aplicaciÃ³n WinUI 3 utilizando .NET y el paquete Microsoft.ML.OnnxRuntime. Se presentarÃ¡ un caso prÃ¡ctico de clasificaciÃ³n de imagenes con un modelo preentrenado."><meta property="og:locale" content="es"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-06-11T00:00:00-03:00"><meta property="article:modified_time" content="2025-06-11T00:00:00-03:00"><meta property="article:tag" content="WinDev"><meta property="article:tag" content="Windows 11"><meta property="article:tag" content="WinUI 3"><script async src="https://www.googletagmanager.com/gtag/js?id=G-V1ZRP82YFD"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-V1ZRP82YFD")</script><link rel=canonical href=https://cmas.dev/posts/2025-06-11-wsl2-winui3-local-models-ai/><link rel=preload href=/fonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin><link rel=preload href=/fonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin><link rel=stylesheet href=/css/coder.min.7763f8bc6341ecf82378e867c285e1549abb063a899be313ccd25dbfcd24fa7d.css integrity="sha256-d2P4vGNB7PgjeOhnwoXhVJq7BjqJm+MTzNJdv80k+n0=" crossorigin=anonymous media=screen><link rel=stylesheet href=/css/coder-dark.min.a00e6364bacbc8266ad1cc81230774a1397198f8cfb7bcba29b7d6fcb54ce57f.css integrity="sha256-oA5jZLrLyCZq0cyBIwd0oTlxmPjPt7y6KbfW/LVM5X8=" crossorigin=anonymous media=screen><link rel=apple-touch-icon sizes=57x57 href=/img/apple-icon-57x57.png><link rel=apple-touch-icon sizes=60x60 href=/img/apple-icon-60x60.png><link rel=apple-touch-icon sizes=72x72 href=/img/apple-icon-72x72.png><link rel=apple-touch-icon sizes=76x76 href=/img/apple-icon-76x76.png><link rel=apple-touch-icon sizes=114x114 href=/img/apple-icon-114x114.png><link rel=apple-touch-icon sizes=120x120 href=/img/apple-icon-120x120.png><link rel=apple-touch-icon sizes=144x144 href=/img/apple-icon-144x144.png><link rel=apple-touch-icon sizes=152x152 href=/img/apple-icon-152x152.png><link rel=apple-touch-icon sizes=180x180 href=/img/apple-icon-180x180.png><link rel=icon type=image/png sizes=192x192 href=/img/android-icon-192x192.png><link rel=icon type=image/png sizes=32x32 href=/img/favicon-32x32.png><link rel=icon type=image/png sizes=96x96 href=/img/favicon-96x96.png><link rel=icon type=image/png sizes=16x16 href=/img/favicon-16x16.png><link rel=manifest href=/img/manifest.json><meta name=msapplication-TileColor content="#ffffff"><meta name=msapplication-TileImage content="/img/ms-icon-144x144.png"><meta name=theme-color content="#ffffff"><link rel=mask-icon href=/img/safari-pinned-tab.svg color=#5bbad5></head><body class="preload-transitions colorscheme-auto"><div class=float-container><a id=dark-mode-toggle class=colorscheme-toggle><i class="fa-solid fa-adjust fa-fw" aria-hidden=true></i></a></div><main class=wrapper><nav class=navigation><section class=container><a class=navigation-title href=https://cmas.dev/>Christian Amado
</a><input type=checkbox id=menu-toggle>
<label class="menu-button float-right" for=menu-toggle><i class="fa-solid fa-bars fa-fw" aria-hidden=true></i></label><ul class=navigation-list><li class=navigation-item><a class=navigation-link href=/posts/>Blog</a></li><li class=navigation-item><a class=navigation-link href=/about>BiografÃ­a</a></li><li class=navigation-item><a class=navigation-link href=/contact>Contacto</a></li><li class=navigation-item><a class=navigation-link href=/diabetes>Diabetes</a></li><li class=navigation-item><a class=navigation-link href=/tags>Etiquetas</a></li><li class="navigation-item menu-separator"><span>|</span></li><li class=navigation-item><a href=/en/>ðŸ‡ºðŸ‡¸</a></li></ul></section></nav><div class=content><section class="container post"><article><header><div class=post-title><h1 class=title><a class=title-link href=https://cmas.dev/posts/2025-06-11-wsl2-winui3-local-models-ai/>Â¿CÃ³mo ejecutar modelos de IA locales desde una app WinUI 3?</a></h1></div><div class=post-meta><div class=date><span class=posted-on><i class="fa-solid fa-calendar" aria-hidden=true></i>
<time datetime=2025-06-11T00:00:00-03:00>junio 11, 2025
</time></span><span class=reading-time><i class="fa-solid fa-clock" aria-hidden=true></i>
3 minutos de lectura.</span></div><div class=tags><i class="fa-solid fa-tag" aria-hidden=true></i>
<span class=tag><a href=/tags/windev/>WinDev</a>
</span><span class=separator>â€¢</span>
<span class=tag><a href=/tags/windows-11/>Windows 11</a>
</span><span class=separator>â€¢</span>
<span class=tag><a href=/tags/winui-3/>WinUI 3</a></span></div></div></header><div class=post-content><p>La inteligencia artificial estÃ¡ redefiniendo la experiencia del usuario en aplicaciones modernas, y las aplicaciones nativas de <strong>Windows</strong> no son la excepciÃ³n. Gracias a <strong>ONNX Runtime</strong>, es posible ejecutar modelos de inferencia de manera eficiente <strong>sin necesidad de conectarse a la nube</strong>, lo cual es ideal para escenarios desconectados, privados o de alto rendimiento.</p><p>Este artÃ­culo muestra cÃ³mo integrar un modelo <strong>ONNX</strong> en una aplicaciÃ³n <strong>WinUI 3</strong> utilizando <strong>.NET</strong> y el paquete <code>Microsoft.ML.OnnxRuntime</code>. Se presentarÃ¡ un caso prÃ¡ctico de clasificaciÃ³n de imagenes con un modelo preentrenado.</p><h2 id=requisitos-previos>Requisitos previos
<a class=heading-link href=#requisitos-previos><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><ul><li>Visual Studio 2022 o superior</li><li>Windows App SDK 1.5+</li><li>Modelo ONNX (ej: SqueezeNet v1.1)</li><li>Paquetes NuGet:<ul><li><code>Microsoft.ML.OnnxRuntime</code></li><li><code>Microsoft.ML.OnnxRuntime.Managed</code></li></ul></li></ul><h2 id=paso-1-preparar-el-proyecto-winui-3>Paso 1: Preparar el proyecto WinUI 3
<a class=heading-link href=#paso-1-preparar-el-proyecto-winui-3><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>Crear un nuevo proyecto en Visual Studio:</p><ol><li>Plantilla: <strong>Blank App, Packaged (WinUI 3 in Desktop)</strong></li><li>Nombre: <code>WinUI3ONNXDemo</code></li><li>Asegurarse de que el proyecto estÃ© utilizando .NET 6 o superior.</li></ol><p>Agregar los paquetes NuGet:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>Install-Package Microsoft.ML.OnnxRuntime
</span></span><span class=line><span class=cl>Install-Package Microsoft.ML.OnnxRuntime.Managed
</span></span></code></pre></div><p>Agregar el modelo <code>.onnx</code> a la carpeta <code>Assets/Models/</code> del proyecto y configurar la propiedad <strong>Copy to Output Directory</strong> como <code>Copy if newer</code>.</p><h2 id=paso-2-cargar-el-modelo-y-ejecutar-inferencia>Paso 2: Cargar el modelo y ejecutar inferencia
<a class=heading-link href=#paso-2-cargar-el-modelo-y-ejecutar-inferencia><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>Crear una clase de servicio para gestionar la inferencia:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-csharp data-lang=csharp><span class=line><span class=cl><span class=k>using</span> <span class=nn>Microsoft.ML.OnnxRuntime</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=k>using</span> <span class=nn>Microsoft.ML.OnnxRuntime.Tensors</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=k>using</span> <span class=nn>System.Drawing</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kd>public</span> <span class=k>class</span> <span class=nc>OnnxImageClassifier</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kd>private</span> <span class=n>InferenceSession</span> <span class=n>_session</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=kd>public</span> <span class=n>OnnxImageClassifier</span><span class=p>(</span><span class=kt>string</span> <span class=n>modelPath</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=n>_session</span> <span class=p>=</span> <span class=k>new</span> <span class=n>InferenceSession</span><span class=p>(</span><span class=n>modelPath</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=kd>public</span> <span class=kt>string</span> <span class=n>Classify</span><span class=p>(</span><span class=kt>float</span><span class=p>[]</span> <span class=n>input</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=kt>var</span> <span class=n>tensor</span> <span class=p>=</span> <span class=k>new</span> <span class=n>DenseTensor</span><span class=p>&lt;</span><span class=kt>float</span><span class=p>&gt;(</span><span class=n>input</span><span class=p>,</span> <span class=k>new</span><span class=p>[]</span> <span class=p>{</span> <span class=m>1</span><span class=p>,</span> <span class=m>3</span><span class=p>,</span> <span class=m>224</span><span class=p>,</span> <span class=m>224</span> <span class=p>});</span>
</span></span><span class=line><span class=cl>        <span class=kt>var</span> <span class=n>inputMeta</span> <span class=p>=</span> <span class=k>new</span> <span class=n>NamedOnnxValue</span><span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=n>NamedOnnxValue</span><span class=p>.</span><span class=n>CreateFromTensor</span><span class=p>(</span><span class=s>&#34;data&#34;</span><span class=p>,</span> <span class=n>tensor</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>};</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>using</span> <span class=nn>var</span> <span class=n>results</span> <span class=p>=</span> <span class=n>_session</span><span class=p>.</span><span class=n>Run</span><span class=p>(</span><span class=n>inputMeta</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=kt>var</span> <span class=n>output</span> <span class=p>=</span> <span class=n>results</span><span class=p>.</span><span class=n>First</span><span class=p>().</span><span class=n>AsEnumerable</span><span class=p>&lt;</span><span class=kt>float</span><span class=p>&gt;().</span><span class=n>ToArray</span><span class=p>();</span>
</span></span><span class=line><span class=cl>        <span class=kt>var</span> <span class=n>max</span> <span class=p>=</span> <span class=n>output</span><span class=p>.</span><span class=n>Max</span><span class=p>();</span>
</span></span><span class=line><span class=cl>        <span class=kt>var</span> <span class=n>index</span> <span class=p>=</span> <span class=n>Array</span><span class=p>.</span><span class=n>IndexOf</span><span class=p>(</span><span class=n>output</span><span class=p>,</span> <span class=n>max</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=s>$&#34;Clase {index} - Score: {max:F3}&#34;</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><blockquote><p>Nota: La entrada debe estar normalizada al formato del modelo ONNX (e.g., 224x224, RGB, normalizado entre 0 y 1). Para simplificar, puede utilizarse una librerÃ­a como <code>ImageSharp</code> para preparar los datos.</p></blockquote><h2 id=paso-3-interfaz-en-winui-3>Paso 3: Interfaz en WinUI 3
<a class=heading-link href=#paso-3-interfaz-en-winui-3><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>En <code>MainWindow.xaml</code>, incluir controles para cargar una imagen y mostrar la clasificaciÃ³n:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-xml data-lang=xml><span class=line><span class=cl><span class=nt>&lt;StackPanel</span> <span class=na>Spacing=</span><span class=s>&#34;12&#34;</span> <span class=na>Padding=</span><span class=s>&#34;24&#34;</span><span class=nt>&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;Button</span> <span class=na>Content=</span><span class=s>&#34;Seleccionar imagen&#34;</span> <span class=na>Click=</span><span class=s>&#34;OnSelectImageClicked&#34;</span> <span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;Image</span> <span class=na>x:Name=</span><span class=s>&#34;PreviewImage&#34;</span> <span class=na>Width=</span><span class=s>&#34;300&#34;</span> <span class=na>Height=</span><span class=s>&#34;300&#34;</span> <span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;TextBlock</span> <span class=na>x:Name=</span><span class=s>&#34;ResultText&#34;</span> <span class=na>FontSize=</span><span class=s>&#34;20&#34;</span> <span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/StackPanel&gt;</span>
</span></span></code></pre></div><p>En <code>MainWindow.xaml.cs</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-csharp data-lang=csharp><span class=line><span class=cl><span class=kd>private</span> <span class=n>OnnxImageClassifier</span> <span class=n>_classifier</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kd>public</span> <span class=n>MainWindow</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=k>this</span><span class=p>.</span><span class=n>InitializeComponent</span><span class=p>();</span>
</span></span><span class=line><span class=cl>    <span class=kt>var</span> <span class=n>modelPath</span> <span class=p>=</span> <span class=n>Path</span><span class=p>.</span><span class=n>Combine</span><span class=p>(</span><span class=n>AppContext</span><span class=p>.</span><span class=n>BaseDirectory</span><span class=p>,</span> <span class=s>&#34;Assets&#34;</span><span class=p>,</span> <span class=s>&#34;Models&#34;</span><span class=p>,</span> <span class=s>&#34;squeezenet.onnx&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>_classifier</span> <span class=p>=</span> <span class=k>new</span> <span class=n>OnnxImageClassifier</span><span class=p>(</span><span class=n>modelPath</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kd>private</span> <span class=kd>async</span> <span class=k>void</span> <span class=n>OnSelectImageClicked</span><span class=p>(</span><span class=kt>object</span> <span class=n>sender</span><span class=p>,</span> <span class=n>RoutedEventArgs</span> <span class=n>e</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=kt>var</span> <span class=n>picker</span> <span class=p>=</span> <span class=k>new</span> <span class=n>FileOpenPicker</span><span class=p>();</span>
</span></span><span class=line><span class=cl>    <span class=n>picker</span><span class=p>.</span><span class=n>FileTypeFilter</span><span class=p>.</span><span class=n>Add</span><span class=p>(</span><span class=s>&#34;.jpg&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>    <span class=n>picker</span><span class=p>.</span><span class=n>FileTypeFilter</span><span class=p>.</span><span class=n>Add</span><span class=p>(</span><span class=s>&#34;.png&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>WinRT</span><span class=p>.</span><span class=n>Interop</span><span class=p>.</span><span class=n>InitializeWithWindow</span><span class=p>.</span><span class=n>Initialize</span><span class=p>(</span><span class=n>picker</span><span class=p>,</span> <span class=k>this</span><span class=p>.</span><span class=n>GetWindowHandle</span><span class=p>());</span>
</span></span><span class=line><span class=cl>    <span class=kt>var</span> <span class=n>file</span> <span class=p>=</span> <span class=k>await</span> <span class=n>picker</span><span class=p>.</span><span class=n>PickSingleFileAsync</span><span class=p>();</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=p>(</span><span class=n>file</span> <span class=p>!=</span> <span class=kc>null</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=k>using</span> <span class=nn>var</span> <span class=n>stream</span> <span class=p>=</span> <span class=k>await</span> <span class=n>file</span><span class=p>.</span><span class=n>OpenStreamForReadAsync</span><span class=p>();</span>
</span></span><span class=line><span class=cl>        <span class=kt>var</span> <span class=n>input</span> <span class=p>=</span> <span class=n>PreprocessImage</span><span class=p>(</span><span class=n>stream</span><span class=p>);</span> <span class=c1>// convertir a float[]</span>
</span></span><span class=line><span class=cl>        <span class=kt>var</span> <span class=n>result</span> <span class=p>=</span> <span class=n>_classifier</span><span class=p>.</span><span class=n>Classify</span><span class=p>(</span><span class=n>input</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=n>ResultText</span><span class=p>.</span><span class=n>Text</span> <span class=p>=</span> <span class=n>result</span><span class=p>;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><h2 id=paso-4-empaquetado-y-despliegue>Paso 4: Empaquetado y despliegue
<a class=heading-link href=#paso-4-empaquetado-y-despliegue><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><ul><li>Incluir el modelo <code>.onnx</code> en la MSIX.</li><li>Probar en equipos sin acceso a internet.</li><li>Verificar uso de CPU o GPU dependiendo del backend de ONNX.</li></ul><p>Opcionalmente, agregar soporte a DirectML o delegados personalizados para GPU.</p><h2 id=conclusiÃ³n>ConclusiÃ³n
<a class=heading-link href=#conclusi%c3%b3n><i class="fa-solid fa-link" aria-hidden=true title="Link to heading"></i>
<span class=sr-only>Link to heading</span></a></h2><p>Gracias a <strong>ONNX Runtime</strong>, las aplicaciones <strong>WinUI 3</strong> pueden ejecutar modelos de inferencia localmente, lo que abre la puerta a aplicaciones de <strong>IA</strong> privadas, desconectadas o de bajo costo de infraestructura. Esta capacidad es particularmente poderosa en escenarios de <em>Edge Computing</em>, <em>kioscos</em>, diagnÃ³sticos offline o soluciones de accesibilidad personalizadas.</p><p>La combinaciÃ³n de <strong>IA local + UI nativa</strong> representa uno de los pilares del futuro del ecosistema Windows.</p></div><footer><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//cmasblog.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}(),document.addEventListener("themeChanged",function(){document.readyState=="complete"&&DISQUS.reset({reload:!0,config:disqus_config})})</script></footer></article></section></div><footer class=footer><section class=container>Â©
2018 -
2025
Christian Amado
Â·
Desarrollado por <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> & <a href=https://github.com/luizdepra/hugo-coder/ target=_blank rel=noopener>Coder</a>.</section></footer></main><script src=/js/coder.min.6ae284be93d2d19dad1f02b0039508d9aab3180a12a06dcc71b0b0ef7825a317.js integrity="sha256-auKEvpPS0Z2tHwKwA5UI2aqzGAoSoG3McbCw73gloxc="></script><script async src="https://www.googletagmanager.com/gtag/js?id=356375808"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","356375808")}</script><script async src="https://www.googletagmanager.com/gtag/js?id=013131931956450466198%3ablhmkdpweyq"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","013131931956450466198:blhmkdpweyq")</script></body></html>
<!DOCTYPE html>
<html lang="es">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <title>
  Integraci√≥n de inferencia local ONNX con Windows ML en apps modernas ¬∑ Christian Amado
</title>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="color-scheme" content="light dark">




<meta name="author" content="Christian Amado">
<meta name="description" content="La inteligencia artificial en el entorno de escritorio ya no est√° limitada a la nube. Windows proporciona soporte nativo para la ejecuci√≥n de modelos ONNX directamente desde una app WinUI 3 utilizando Windows ML. Esto permite realizar inferencia local con alto rendimiento y sin necesidad de conexi√≥n a internet, ideal para escenarios de privacidad, baja latencia o ejecuci√≥n offline.
En este art√≠culo se describe c√≥mo integrar un modelo ONNX a una app moderna, c√≥mo usar la API de Windows ML y c√≥mo estructurar un flujo de inferencia optimizado con soporte para entrada y salida de datos reales.">
<meta name="keywords" content="blog,desarrollador,personal">



  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Integraci√≥n de inferencia local ONNX con Windows ML en apps modernas">
  <meta name="twitter:description" content="La inteligencia artificial en el entorno de escritorio ya no est√° limitada a la nube. Windows proporciona soporte nativo para la ejecuci√≥n de modelos ONNX directamente desde una app WinUI 3 utilizando Windows ML. Esto permite realizar inferencia local con alto rendimiento y sin necesidad de conexi√≥n a internet, ideal para escenarios de privacidad, baja latencia o ejecuci√≥n offline.
En este art√≠culo se describe c√≥mo integrar un modelo ONNX a una app moderna, c√≥mo usar la API de Windows ML y c√≥mo estructurar un flujo de inferencia optimizado con soporte para entrada y salida de datos reales.">

<meta property="og:url" content="http://localhost:1313/es/posts/2025-03-21-onnx-windows-ml/">
  <meta property="og:site_name" content="Christian Amado">
  <meta property="og:title" content="Integraci√≥n de inferencia local ONNX con Windows ML en apps modernas">
  <meta property="og:description" content="La inteligencia artificial en el entorno de escritorio ya no est√° limitada a la nube. Windows proporciona soporte nativo para la ejecuci√≥n de modelos ONNX directamente desde una app WinUI 3 utilizando Windows ML. Esto permite realizar inferencia local con alto rendimiento y sin necesidad de conexi√≥n a internet, ideal para escenarios de privacidad, baja latencia o ejecuci√≥n offline.
En este art√≠culo se describe c√≥mo integrar un modelo ONNX a una app moderna, c√≥mo usar la API de Windows ML y c√≥mo estructurar un flujo de inferencia optimizado con soporte para entrada y salida de datos reales.">
  <meta property="og:locale" content="es">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-03-21T00:00:00-04:00">
    <meta property="article:modified_time" content="2025-03-21T00:00:00-04:00">
    <meta property="article:tag" content="WinDev">
    <meta property="article:tag" content="Windows 11">
    <meta property="article:tag" content="WinUI 3">
    <meta property="article:tag" content="Windows App SDK">




<link rel="canonical" href="http://localhost:1313/es/posts/2025-03-21-onnx-windows-ml/">


<link rel="preload" href="/fonts/fa-brands-400.woff2" as="font" type="font/woff2" crossorigin>
<link rel="preload" href="/fonts/fa-regular-400.woff2" as="font" type="font/woff2" crossorigin>
<link rel="preload" href="/fonts/fa-solid-900.woff2" as="font" type="font/woff2" crossorigin>


  
  
  <link rel="stylesheet" href="/css/coder.css" media="screen">






  
    
    
    <link rel="stylesheet" href="/css/coder-dark.css" media="screen">
  



 




<link rel="icon" type="image/svg+xml" href="/images/favicon.svg" sizes="any">
<link rel="icon" type="image/png" href="/images/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/images/favicon-16x16.png" sizes="16x16">

<link rel="apple-touch-icon" href="/images/apple-touch-icon.png">
<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="manifest" href="/site.webmanifest">
<link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#5bbad5">









</head>






<body class="preload-transitions colorscheme-auto">
  
<div class="float-container">
    <a id="dark-mode-toggle" class="colorscheme-toggle">
        <i class="fa-solid fa-adjust fa-fw" aria-hidden="true"></i>
    </a>
</div>


  <main class="wrapper">
    <nav class="navigation">
  <section class="container">
    
    <a class="navigation-title" href="http://localhost:1313/es/">
      Christian Amado
    </a>
    
    
      <input type="checkbox" id="menu-toggle" />
      <label class="menu-button float-right" for="menu-toggle">
        <i class="fa-solid fa-bars fa-fw" aria-hidden="true"></i>
      </label>
      <ul class="navigation-list">
        
          
            <li class="navigation-item">
              <a class="navigation-link " href="/es/posts/">Blog</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link " href="/es/about">Biograf√≠a</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link " href="/es/contact">Contacto</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link " href="/es/diabetes">Diabetes</a>
            </li>
          
            <li class="navigation-item">
              <a class="navigation-link " href="/es/tags">Etiquetas</a>
            </li>
          
        
        
          
          
          
            
          
            
              
                <li class="navigation-item menu-separator">
                  <span>|</span>
                </li>
                
              
              <li class="navigation-item">
                <a href="/en/">üá∫üá∏</a>
              </li>
            
          
        
      </ul>
    
  </section>
</nav>


    <div class="content">
      
  <section class="container post">
    <article>
      <header>
        <div class="post-title">
          <h1 class="title">
            <a class="title-link" href="http://localhost:1313/es/posts/2025-03-21-onnx-windows-ml/">
              Integraci√≥n de inferencia local ONNX con Windows ML en apps modernas
            </a>
          </h1>
        </div>
        <div class="post-meta">
          <div class="date">
            <span class="posted-on">
              <i class="fa-solid fa-calendar" aria-hidden="true"></i>
              <time datetime="2025-03-21T00:00:00-04:00">
                marzo 21, 2025
              </time>
            </span>
            <span class="reading-time">
              <i class="fa-solid fa-clock" aria-hidden="true"></i>
              3 minutos de lectura.
            </span>
          </div>
          
          
          <div class="tags">
  <i class="fa-solid fa-tag" aria-hidden="true"></i>
    <span class="tag">
      <a href="/es/tags/windev/">WinDev</a>
    </span>
      <span class="separator">‚Ä¢</span>
    <span class="tag">
      <a href="/es/tags/windows-11/">Windows 11</a>
    </span>
      <span class="separator">‚Ä¢</span>
    <span class="tag">
      <a href="/es/tags/winui-3/">WinUI 3</a>
    </span>
      <span class="separator">‚Ä¢</span>
    <span class="tag">
      <a href="/es/tags/windows-app-sdk/">Windows App SDK</a>
    </span></div>

        </div>
      </header>

      <div class="post-content">
        
        <p>La inteligencia artificial en el entorno de escritorio ya no est√° limitada a la nube. <strong>Windows</strong> proporciona soporte nativo para la ejecuci√≥n de modelos <strong>ONNX</strong> directamente desde una app <strong>WinUI 3</strong> utilizando <strong>Windows ML</strong>. Esto permite realizar inferencia local con alto rendimiento y sin necesidad de conexi√≥n a internet, ideal para escenarios de privacidad, baja latencia o ejecuci√≥n offline.</p>
<p>En este art√≠culo se describe c√≥mo integrar un modelo <strong>ONNX</strong> a una app moderna, c√≥mo usar la <strong>API</strong> de <strong>Windows ML</strong> y c√≥mo estructurar un flujo de inferencia optimizado con soporte para entrada y salida de datos reales.</p>
<h2 id="requisitos">
  Requisitos
  <a class="heading-link" href="#requisitos">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<ul>
<li>Windows 11 (recomendado build 22621+)</li>
<li>Visual Studio 2022 con Windows App SDK 1.3+</li>
<li>Proyecto WinUI 3 empaquetado (MSIX)</li>
<li>Referencia al paquete <code>Microsoft.AI.MachineLearning</code></li>
<li>Modelo ONNX compatible (puede ser descargado de onnxruntime zoo)</li>
</ul>
<h2 id="paso-1-agregar-el-paquete-nuget-de-windows-ml">
  Paso 1: Agregar el paquete NuGet de Windows ML
  <a class="heading-link" href="#paso-1-agregar-el-paquete-nuget-de-windows-ml">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<p>Agregar al proyecto:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">Install-Package Microsoft.AI.MachineLearning
</span></span></code></pre></div><p>Esto permite cargar y ejecutar modelos ONNX directamente desde c√≥digo.</p>
<h2 id="paso-2-copiar-el-modelo-onnx-al-proyecto">
  Paso 2: Copiar el modelo ONNX al proyecto
  <a class="heading-link" href="#paso-2-copiar-el-modelo-onnx-al-proyecto">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<p>Ejemplo: <code>modelo_mnist.onnx</code> copiado a la carpeta <code>Assets/ML</code></p>
<p>Configurar en propiedades:</p>
<ul>
<li>Build Action: Content</li>
<li>Copy to Output Directory: Copy if newer</li>
</ul>
<h2 id="paso-3-cargar-el-modelo-onnx">
  Paso 3: Cargar el modelo ONNX
  <a class="heading-link" href="#paso-3-cargar-el-modelo-onnx">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<p>Importar:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-csharp" data-lang="csharp"><span class="line"><span class="cl"><span class="k">using</span> <span class="nn">Microsoft.AI.MachineLearning</span><span class="p">;</span>
</span></span></code></pre></div><p>Cargar desde archivo:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-csharp" data-lang="csharp"><span class="line"><span class="cl"><span class="kt">var</span> <span class="n">file</span> <span class="p">=</span> <span class="k">await</span> <span class="n">StorageFile</span><span class="p">.</span><span class="n">GetFileFromApplicationUriAsync</span><span class="p">(</span><span class="k">new</span> <span class="n">Uri</span><span class="p">(</span><span class="s">&#34;ms-appx:///Assets/ML/modelo_mnist.onnx&#34;</span><span class="p">));</span>
</span></span><span class="line"><span class="cl"><span class="kt">var</span> <span class="n">session</span> <span class="p">=</span> <span class="n">LearningModelSession</span><span class="p">.</span><span class="n">CreateFromModel</span><span class="p">(</span><span class="n">LearningModel</span><span class="p">.</span><span class="n">LoadFromFilePath</span><span class="p">(</span><span class="n">file</span><span class="p">.</span><span class="n">Path</span><span class="p">));</span>
</span></span></code></pre></div><p>Esto crea una sesi√≥n de inferencia desde el modelo.</p>
<h2 id="paso-4-preparar-entrada-para-inferencia">
  Paso 4: Preparar entrada para inferencia
  <a class="heading-link" href="#paso-4-preparar-entrada-para-inferencia">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<p>Ejemplo para imagen de 28x28 p√≠xeles escala de grises:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-csharp" data-lang="csharp"><span class="line"><span class="cl"><span class="kt">float</span><span class="p">[]</span> <span class="n">input</span> <span class="p">=</span> <span class="k">new</span> <span class="kt">float</span><span class="p">[</span><span class="m">1</span> <span class="p">*</span> <span class="m">1</span> <span class="p">*</span> <span class="m">28</span> <span class="p">*</span> <span class="m">28</span><span class="p">];</span> <span class="c1">// NCHW</span>
</span></span><span class="line"><span class="cl"><span class="c1">// Rellenar input con los valores de p√≠xeles normalizados (0.0‚Äì1.0)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">var</span> <span class="n">tensor</span> <span class="p">=</span> <span class="n">TensorFloat</span><span class="p">.</span><span class="n">CreateFromArray</span><span class="p">(</span><span class="k">new</span><span class="p">[]</span> <span class="p">{</span> <span class="m">1</span><span class="n">u</span><span class="p">,</span> <span class="m">1</span><span class="n">u</span><span class="p">,</span> <span class="m">28</span><span class="n">u</span><span class="p">,</span> <span class="m">28</span><span class="n">u</span> <span class="p">},</span> <span class="n">input</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="kt">var</span> <span class="n">binding</span> <span class="p">=</span> <span class="k">new</span> <span class="n">LearningModelBinding</span><span class="p">(</span><span class="n">session</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="n">binding</span><span class="p">.</span><span class="n">Bind</span><span class="p">(</span><span class="s">&#34;Input3&#34;</span><span class="p">,</span> <span class="n">tensor</span><span class="p">);</span>
</span></span></code></pre></div><h2 id="paso-5-ejecutar-inferencia">
  Paso 5: Ejecutar inferencia
  <a class="heading-link" href="#paso-5-ejecutar-inferencia">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-csharp" data-lang="csharp"><span class="line"><span class="cl"><span class="kt">var</span> <span class="n">result</span> <span class="p">=</span> <span class="k">await</span> <span class="n">session</span><span class="p">.</span><span class="n">EvaluateAsync</span><span class="p">(</span><span class="n">binding</span><span class="p">,</span> <span class="s">&#34;Inferencia1&#34;</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="kt">var</span> <span class="n">outputTensor</span> <span class="p">=</span> <span class="n">result</span><span class="p">.</span><span class="n">Outputs</span><span class="p">[</span><span class="s">&#34;Plus214_Output_0&#34;</span><span class="p">]</span> <span class="k">as</span> <span class="n">TensorFloat</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="kt">var</span> <span class="n">output</span> <span class="p">=</span> <span class="n">outputTensor</span><span class="p">.</span><span class="n">GetAsVectorView</span><span class="p">();</span>
</span></span><span class="line"><span class="cl"><span class="kt">int</span> <span class="n">predictedIndex</span> <span class="p">=</span> <span class="n">output</span><span class="p">.</span><span class="n">ToList</span><span class="p">().</span><span class="n">IndexOf</span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="n">Max</span><span class="p">());</span>
</span></span></code></pre></div><p>Esto retorna el √≠ndice con mayor probabilidad (en este caso, el d√≠gito 0‚Äì9).</p>
<h2 id="paso-6-mostrar-resultados-en-ui">
  Paso 6: Mostrar resultados en UI
  <a class="heading-link" href="#paso-6-mostrar-resultados-en-ui">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-csharp" data-lang="csharp"><span class="line"><span class="cl"><span class="n">ResultadoText</span><span class="p">.</span><span class="n">Text</span> <span class="p">=</span> <span class="s">$&#34;Predicci√≥n: {predictedIndex}&#34;</span><span class="p">;</span>
</span></span></code></pre></div><p>En XAML:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-xml" data-lang="xml"><span class="line"><span class="cl"><span class="nt">&lt;StackPanel&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;Image</span> <span class="na">x:Name=</span><span class="s">&#34;InputPreview&#34;</span><span class="nt">/&gt;</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&lt;TextBlock</span> <span class="na">x:Name=</span><span class="s">&#34;ResultadoText&#34;</span><span class="nt">/&gt;</span>
</span></span><span class="line"><span class="cl"><span class="nt">&lt;/StackPanel&gt;</span>
</span></span></code></pre></div><h2 id="paso-7-optimizaci√≥n-y-aceleraci√≥n">
  Paso 7: Optimizaci√≥n y aceleraci√≥n
  <a class="heading-link" href="#paso-7-optimizaci%c3%b3n-y-aceleraci%c3%b3n">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<p>Windows ML usa DirectML y soporte para GPU si est√° disponible. No se requiere configuraci√≥n extra: el runtime lo detecta autom√°ticamente.</p>
<p>Validar el dispositivo utilizado:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-csharp" data-lang="csharp"><span class="line"><span class="cl"><span class="kt">var</span> <span class="n">deviceKind</span> <span class="p">=</span> <span class="n">session</span><span class="p">.</span><span class="n">DeviceKind</span><span class="p">.</span><span class="n">ToString</span><span class="p">();</span> <span class="c1">// CPU, GPU, DirectML</span>
</span></span></code></pre></div><h2 id="paso-8-alternativas-para-modelos">
  Paso 8: Alternativas para modelos
  <a class="heading-link" href="#paso-8-alternativas-para-modelos">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<ul>
<li>Convertir PyTorch / TensorFlow ‚Üí ONNX</li>
<li>Usar modelos preentrenados: <code>squeezenet</code>, <code>resnet18</code>, <code>mobilenetv2</code></li>
<li>Exportar modelos propios con herramientas como <code>onnxruntime-tools</code> o <code>tf2onnx</code></li>
</ul>
<h2 id="casos-de-uso-reales">
  Casos de uso reales
  <a class="heading-link" href="#casos-de-uso-reales">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<ul>
<li>Clasificaci√≥n de im√°genes (productos, documentos)</li>
<li>Detecci√≥n de anomal√≠as locales</li>
<li>Asistentes inteligentes offline</li>
<li>Modelos de NLP ligeros ejecutados localmente</li>
<li>Reconocimiento de escritura a mano o n√∫meros</li>
</ul>
<h2 id="buenas-pr√°cticas">
  Buenas pr√°cticas
  <a class="heading-link" href="#buenas-pr%c3%a1cticas">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<ul>
<li>Validar entradas antes de ejecutar inferencia</li>
<li>Manejar fallback si no hay aceleraci√≥n GPU</li>
<li>No cargar el modelo en cada inferencia (persistir sesi√≥n)</li>
<li>Reducir tama√±o del modelo con quantization si es posible</li>
</ul>
<h2 id="conclusi√≥n">
  Conclusi√≥n
  <a class="heading-link" href="#conclusi%c3%b3n">
    <i class="fa-solid fa-link" aria-hidden="true" title="Link to heading"></i>
    <span class="sr-only">Link to heading</span>
  </a>
</h2>
<p>La integraci√≥n de <strong>ONNX</strong> y <strong>Windows ML</strong> en aplicaciones modernas <strong>WinUI 3</strong> permite ejecutar inferencia local de modelos de IA de forma nativa, segura y sin latencia de red. Esto convierte a <strong>Windows</strong> en una plataforma ideal para aplicaciones inteligentes en el borde, desde escritorios empresariales hasta dispositivos aut√≥nomos. El soporte de <strong>Windows App SDK</strong> lo hace accesible a cualquier desarrollador de apps modernas.</p>
      </div>


      <footer>
        


        <div id="disqus_thread"></div>
<script>
  window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "cmasblog" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
    
    document.addEventListener('themeChanged', function (e) { 
        if (document.readyState == 'complete') {
          DISQUS.reset({ reload: true, config: disqus_config });
        }
    });
</script>
        
        
        
        
        
        
      </footer>
    </article>

    
  </section>

    </div>

    <footer class="footer">
  <section class="container">
    ¬©
    
      2018 -
    
    2025
     Christian Amado 
    ¬∑
    
    Desarrollado por <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> & <a href="https://github.com/luizdepra/hugo-coder/" target="_blank" rel="noopener">Coder</a>.
    
  </section>
</footer>

  </main>

  

  
  
  <script src="/js/coder.js"></script>
  

  

  


  
      <script async src="https://www.googletagmanager.com/gtag/js?id=356375808"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', '356375808');
        }
      </script>

  

  

  

  

  

  

  

  
<script async src="https://www.googletagmanager.com/gtag/js?id=013131931956450466198%3ablhmkdpweyq"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', '013131931956450466198:blhmkdpweyq');
</script>


  

  

  

  

  

  

  

  
</body>
</html>
